const OpenAI = require('openai');
const PROMPT_TEMPLATE = process.env.PROMPT_TEMPLATE;
const OPENAI_VECTOR_STORE_ID = process.env.OPENAI_VECTOR_STORE_ID;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

/**
 * @param {Object} params
 * @param {string} params.userMessage
 * @param {string} params.model
 * @param {string|null} params.previousResponseId
 * @param {Array<Object>|null} params.filters
 */
async function* generateStreamResponse({ userMessage, model, previousResponseId = null, filters = null }) {
    try {
        console.info(`Response API File Search開始: '${userMessage}' (Vector Store: ${OPENAI_VECTOR_STORE_ID})`);

        let tools = [];
        if (OPENAI_VECTOR_STORE_ID) {
            const toolsConfig = {
                type: "file_search",
                vector_store_ids: [OPENAI_VECTOR_STORE_ID],
                max_num_results: 10,
                ranking_options: { score_threshold: 0.2 }
            };
            if (filters) {
                toolsConfig.filters = {
                    type: "or",
                    filters: filters
                };
            }
            tools = [toolsConfig];
        } else {
            console.warn("No Vector Store ID provided, skipping file search tool");
        }

        const requestPayload = {
            model: model,
            prompt: { id: PROMPT_TEMPLATE },
            input: [{ role: "user", content: userMessage }],
            tools: tools,
            temperature: 0.7,
            truncation: "auto",
            stream: true,
            text: {
                format: {
                    type: "json_schema",
                    name: "assistant_response",
                    schema: {
                        type: "object",
                        properties: {
                            assistant_response_text: {
                                type: "string",
                                description: "The final text response generated by the assistant based on the file search results or lack thereof."
                            },
                            used_database: {
                                type: "boolean",
                                description: "True if the assistant actually referenced the database (file search) to answer the user's question, false otherwise."
                            }
                        },
                        required: ["assistant_response_text", "used_database"],
                        additionalProperties: false
                    }
                }
            }
        };
        if (previousResponseId) requestPayload.previous_response_id = previousResponseId;

        // OpenAI Node.js SDK v5.x の新しいstreaming API
        const responseStream = await openai.responses.create(requestPayload);

        // responseStreamがAsyncIterableの場合
        for await (const chunk of responseStream) {
            yield `data: ${JSON.stringify(chunk)}\n\n`;
        }

        yield `data: ${JSON.stringify({ completed: true })}\n\n`;

        console.info("Response API stream completed successfully");
    } catch (e) {
        console.error(`Error in generateStreamResponse: ${e}`);
        yield `data: ${JSON.stringify({ error: String(e) })}\n\n`;
    }
}

module.exports = { generateStreamResponse };