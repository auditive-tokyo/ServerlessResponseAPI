import OpenAI from 'openai';
import {
    ResponseCreateParamsStreaming,
    ResponseStreamEvent,
    FileSearchTool
} from 'openai/resources/responses/responses';

const PROMPT_TEMPLATE = process.env.PROMPT_TEMPLATE;
const OPENAI_VECTOR_STORE_ID = process.env.OPENAI_VECTOR_STORE_ID;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

interface Filter {
    key: string;
    type: string;
    value: string | number | boolean;
}

/**
 * generateStreamResponseの戻り値型（OpenAIイベントまたは文字列メッセージ）
 */
export type StreamYield = ResponseStreamEvent | string;

export async function* generateStreamResponse({
    userMessage,
    model,
    previousResponseId = null,
    filters = null,
}: {
    userMessage: string;
    model: string;
    previousResponseId?: string | null;
    filters?: Filter[] | null;
}): AsyncGenerator<StreamYield> {
    try {
        console.info(`Response API File Search開始: '${userMessage}' (Vector Store: ${OPENAI_VECTOR_STORE_ID})`);

        let tools: FileSearchTool[] = [];
        if (OPENAI_VECTOR_STORE_ID) {
            const toolsConfig: FileSearchTool = {
                type: "file_search",
                vector_store_ids: [OPENAI_VECTOR_STORE_ID],
                max_num_results: 10,
                ranking_options: { score_threshold: 0.2 }
            };
            if (filters) {
                toolsConfig.filters = {
                    type: "or",
                    filters: filters
                };
            }
            tools = [toolsConfig];
        } else {
            console.warn("No Vector Store ID provided, skipping file search tool");
        }

        const requestPayload: ResponseCreateParamsStreaming = {
            model: model,
            instructions: PROMPT_TEMPLATE,
            input: userMessage,
            tools: tools,
            temperature: 0.7,
            truncation: "auto",
            stream: true,
            text: {
                format: {
                    type: "json_schema",
                    name: "assistant_response",
                    schema: {
                        type: "object",
                        properties: {
                            assistant_response_text: {
                                type: "string",
                                description: "The final text response generated by the assistant based on the file search results or lack thereof."
                            },
                            reference_files: {
                                type: "array",
                                items: { type: "string" },
                                description: "If the assistant referenced the database (file search), this is a list of referenced file names. Otherwise, it will be an empty array."
                            }
                        },
                        required: ["assistant_response_text", "reference_files"],
                        additionalProperties: false
                    }
                }
            },
            ...(previousResponseId && { previous_response_id: previousResponseId })
        };

        const response = await openai.responses.create(requestPayload);

        for await (const chunk of response as AsyncIterable<ResponseStreamEvent>) {
            yield chunk;
        }

        yield `data: ${JSON.stringify({ completed: true })}\n\n`;

        console.info("Response API stream completed successfully");
    } catch (e) {
        console.error(`Error in generateStreamResponse: ${e}`);
        yield `data: ${JSON.stringify({ error: String(e) })}\n\n`;
    }
}